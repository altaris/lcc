{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1363c419-65a5-4dbb-ba49-ba31efc25604",
   "metadata": {},
   "source": [
    "This notebook is used to check that methods in `correction.clustering` work as expected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c73da7e-6127-4044-b7f8-4c5e2be1aa8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext jupyter_black\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f914d359-9a75-4e99-b08c-666c0469b336",
   "metadata": {},
   "outputs": [],
   "source": [
    "import bokeh.layouts as bkl\n",
    "import bokeh.plotting as bk\n",
    "from bokeh.io import output_notebook\n",
    "\n",
    "from nlnas.plotting import export_png\n",
    "\n",
    "output_notebook()\n",
    "\n",
    "import sys\n",
    "\n",
    "from loguru import logger as logging\n",
    "\n",
    "logging.remove()\n",
    "logging.add(\n",
    "    sys.stdout,\n",
    "    level=\"INFO\",\n",
    "    format=\"[<level>{level: <8}</level>] <level>{message}</level>\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc428ea8-45b6-42d2-9434-a321446fc471",
   "metadata": {},
   "source": [
    "# Loading stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3233c48-6912-41b9-9e59-7de1c270ae85",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import turbo_broccoli as tb\n",
    "\n",
    "HF_DATASET_NAME = \"cifar100\"\n",
    "# HF_MODEL_NAME = \"timm/tinynet_e.in1k\"\n",
    "HF_MODEL_NAME = \"timm/mobilenetv3_small_050.lamb_in1k\"\n",
    "SUBMODULE = \"model.conv_head\"\n",
    "VERSION = 0\n",
    "\n",
    "DATASET_NAME = HF_DATASET_NAME.replace(\"/\", \"-\")\n",
    "MODEL_NAME = HF_MODEL_NAME.replace(\"/\", \"-\")\n",
    "\n",
    "RESULT_FILE_PATH = (\n",
    "    Path(\"out/ftlcc\") / DATASET_NAME / MODEL_NAME / f\"results.{VERSION}.json\"\n",
    ")\n",
    "RESULTS = tb.load_json(RESULT_FILE_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47096111-8423-4bc6-b945-349e64855b4e",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fda30069-f357-42b7-9d56-0335d5a07731",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nlnas.classifiers.timm import TimmClassifier\n",
    "\n",
    "CKPT_PATH = Path(\"out/ftlcc\") / RESULTS[\"model\"][\"best_checkpoint\"][\"path\"]\n",
    "logging.info(\"Best model checkpoint path: {}\", CKPT_PATH)\n",
    "\n",
    "model = TimmClassifier.load_from_checkpoint(CKPT_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9a7f998-ee21-436c-a5f9-e2d6dda3530a",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5d0319e-1b8a-4747-a72e-e201e7d3b786",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nlnas.datasets.huggingface import HuggingFaceDataset\n",
    "\n",
    "dataset = HuggingFaceDataset(\n",
    "    HF_DATASET_NAME,\n",
    "    fit_split=RESULTS[\"dataset\"][\"train_split\"],\n",
    "    val_split=RESULTS[\"dataset\"][\"val_split\"],\n",
    "    test_split=RESULTS[\"dataset\"][\"test_split\"],\n",
    "    predict_split=RESULTS[\"dataset\"][\"train_split\"],  # not a typo\n",
    "    label_key=RESULTS[\"dataset\"][\"label_key\"],\n",
    "    image_processor=model.get_image_processor(HF_MODEL_NAME),\n",
    ")\n",
    "\n",
    "n_classes = dataset.n_classes()\n",
    "y_true = dataset.y_true(\"train\").numpy()\n",
    "logging.info(\"y_true: {}\", y_true.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "006ca343-db11-4f81-b187-450923dbf0f7",
   "metadata": {},
   "source": [
    "## Latent embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77a49d7b-7c41-4361-8b35-3ba8e62bb548",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from nlnas.utils import load_tensor_batched\n",
    "\n",
    "latent_embeddings = load_tensor_batched(\n",
    "    RESULT_FILE_PATH.parent\n",
    "    / \"analysis\"\n",
    "    / str(RESULTS[\"model\"][\"best_checkpoint\"][\"version\"])\n",
    "    / \"embeddings\"\n",
    "    / \"train\",\n",
    "    prefix=SUBMODULE,\n",
    "    tqdm_style=\"notebook\",\n",
    ")\n",
    "latent_embeddings = latent_embeddings.numpy()\n",
    "# latent_embeddings = latent_embeddings.reshape(len(latent_embeddings), -1)\n",
    "# latent_embeddings = StandardScaler().fit_transform(latent_embeddings)\n",
    "\n",
    "logging.info(\"Latent embedding array: {}\", latent_embeddings.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1e81a1a-e68a-41c8-910f-5f9947999236",
   "metadata": {},
   "source": [
    "## Predictions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22ef41c1-edeb-4e5a-90f6-46b29d4bf6d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "logits = load_tensor_batched(\n",
    "    RESULT_FILE_PATH.parent\n",
    "    / \"analysis\"\n",
    "    / str(RESULTS[\"model\"][\"best_checkpoint\"][\"version\"])\n",
    "    / \"embeddings\"\n",
    "    / \"train\",\n",
    "    prefix=\"y_pred\",\n",
    "    tqdm_style=\"notebook\",\n",
    ")\n",
    "logits = logits.numpy()\n",
    "y_pred = logits.argmax(axis=-1)\n",
    "\n",
    "logging.info(\"logits: {}\", logits.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b12f8701-3e1d-40cb-b6c6-4ca7a31873db",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchmetrics.functional.classification import multiclass_accuracy\n",
    "import torch\n",
    "\n",
    "multiclass_accuracy(torch.tensor(logits), torch.tensor(y_true), num_classes=n_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "366391ff-9811-490d-be9e-572c8448bc77",
   "metadata": {},
   "source": [
    "## Clustering data"
   ]
  },
  {
   "cell_type": "raw",
   "id": "6d5f88ff-0851-4360-99b5-706c7975590d",
   "metadata": {},
   "source": [
    "import turbo_broccoli as tb\n",
    "\n",
    "clustering_data = tb.load_json(\n",
    "    RESULT_FILE_PATH.parent\n",
    "    / \"analysis\"\n",
    "    / str(RESULTS[\"model\"][\"best_checkpoint\"][\"version\"])\n",
    "    / \"louvain\"\n",
    "    / \"data.json\",\n",
    ")\n",
    "y_clst, matching = clustering_data[SUBMODULE]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "405c0c9c-b2f4-4c91-b699-9de001b4fe35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recompute the clustering data from scratch\n",
    "\n",
    "from tempfile import TemporaryDirectory\n",
    "\n",
    "from nlnas.classifiers.base import full_dataset_latent_clustering\n",
    "\n",
    "with TemporaryDirectory() as tmp:\n",
    "    lc_data = full_dataset_latent_clustering(\n",
    "        model,\n",
    "        dataset,\n",
    "        tmp,\n",
    "        method=\"louvain\",\n",
    "        device=\"cuda\",\n",
    "        scaling=\"standard\",\n",
    "        classes=None,\n",
    "        split=\"train\",\n",
    "        tqdm_style=\"notebook\",\n",
    "    )\n",
    "\n",
    "y_clst = lc_data[\"model.conv_head\"].y_clst\n",
    "matching = lc_data[\"model.conv_head\"].matching\n",
    "knn_indices = lc_data[\"model.conv_head\"].knn_indices"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccf33851-c526-425a-b9a9-e0892d90a15b",
   "metadata": {},
   "source": [
    "# Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d86d704-db55-47f8-b85b-c254248a352a",
   "metadata": {},
   "source": [
    "## Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66af7f3d-cc1d-440b-a785-653a9b1c4303",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# i_clst -> nb of samples in cluster i_clst\n",
    "clst_size = {i_clst: (y_clst == i_clst).sum() for i_clst in np.unique(y_clst)}\n",
    "\n",
    "# i_true -> nb of samples that are in clustered matched to i_true\n",
    "n_matched = {\n",
    "    i_true: sum(clst_size[j_clst] for j_clst in m) for i_true, m in matching.items()\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bcd8f09-29de-46d1-bf8b-67f0613d4b56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is just for curiosity\n",
    "\n",
    "i_true, n = sorted(n_matched.items(), key=lambda kv: kv[1], reverse=True)[0]\n",
    "logging.info(\n",
    "    (\n",
    "        \"Top true class by number of samples in matched clusters: \\n\"\n",
    "        \"  i_true = {}\\n\"\n",
    "        \"  matched clusters: {}\\n\"\n",
    "        \"  nb. of matched samples: {}\"\n",
    "    ),\n",
    "    i_true,\n",
    "    matching[i_true],\n",
    "    n,\n",
    ")\n",
    "\n",
    "i_true = sorted(matching.keys(), key=lambda lbl: len(matching[lbl]), reverse=True)[0]\n",
    "ns = set(map(lambda j_clst: clst_size[j_clst], matching[i_true]))\n",
    "logging.info(\n",
    "    (\n",
    "        \"Top true class by number of matched clusters: \\n\"\n",
    "        \"  i_true = {}\\n\"\n",
    "        \"  matched clusters: {}\\n\"\n",
    "        \"  nb. of samples in clusters (resp.): {}\\n\"\n",
    "        \"  total nb. of matched samples: {}\"\n",
    "    ),\n",
    "    i_true,\n",
    "    matching[i_true],\n",
    "    ns,\n",
    "    sum(ns),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f0d15a4-cf59-4bac-9859-b2d2d6d06fb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nlnas.correction.clustering import otm_matching_predicates, _mc_cc_predicates\n",
    "\n",
    "p1, p2, p3, p4 = otm_matching_predicates(y_true, y_clst, matching)\n",
    "p_mc, p_cc = _mc_cc_predicates(y_true, y_clst, matching)\n",
    "logging.info(\n",
    "    \"OTM matching predicate shapes: {} {} {} {}\", p1.shape, p2.shape, p3.shape, p4.shape\n",
    ")\n",
    "logging.info(\"MC/CC predicate shapes: {} {}\", p_mc.shape, p_cc.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf5ef169-df88-46b7-a4b8-8e9e95f39f31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing if p1 is what is expected\n",
    "# p1[i_true, j] is True if j-th sample in class i_true\n",
    "\n",
    "for i_true in np.unique(y_true):\n",
    "    a, b = np.where(y_true == i_true)[0], np.where(p1[i_true])[0]\n",
    "    assert len(a) == len(b)\n",
    "    assert (a == b).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35fb2f07-b391-448d-8b13-871c2c601d93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing if p2 is what is expected\n",
    "# p2[i_true, j] is True if j-th sample is in a cluster matched to i_true\n",
    "\n",
    "for i_true in np.unique(y_true):\n",
    "    a = np.where(np.isin(y_clst, list(matching[i_true])))[0]\n",
    "    b = np.where(p2[i_true])[0]\n",
    "    assert len(a) == len(b)\n",
    "    assert (a == b).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99ac6d6a-ebda-4464-97c9-54cf4c3f0a83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing if p3 is what is expected\n",
    "# p3[i_true, j] is True if j-th sample is in true class i_true but not in any\n",
    "# cluster matched to i_true\n",
    "\n",
    "for i_true, p in enumerate(p3):\n",
    "    for j in np.where(p)[0]:\n",
    "        assert y_clst[j] not in matching[i_true]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81498d50-b3a0-47fe-880f-ef51941e8966",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing if p4 is what is expected\n",
    "# p4[i_true, j] is True if j-th sample is NOT in true class i_true but in a\n",
    "# cluster matched to i_true\n",
    "\n",
    "for i_true, p in enumerate(p4):\n",
    "    for j in np.where(p)[0]:\n",
    "        assert y_true[j] != i_true\n",
    "        assert y_clst[j] in matching[i_true]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd4ef286-cde0-45dd-adbc-b0b13e954802",
   "metadata": {},
   "source": [
    "At this point we're confident that the OTM matching predicates are accurate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63de52db-cf38-4598-9ae6-edf24e753d6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing if p_cc is what is expected\n",
    "# p_cc[i_true, j] is True if j-th sample is in true class i_true and in a\n",
    "# cluster matched to i_true\n",
    "\n",
    "for i_true, p in enumerate(p_cc):\n",
    "    for j in np.where(p)[0]:\n",
    "        assert y_true[j] == i_true\n",
    "        assert y_clst[j] in matching[i_true]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41f751a4-3a07-4431-be17-f8f74029b6dd",
   "metadata": {},
   "source": [
    "## KNN indices"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01b42593-62be-4c03-8f9a-02c277bfd809",
   "metadata": {},
   "source": [
    "Here we study the actual `LatentClusteringData` computed by `full_dataset_latent_clustering`, particularly the KNN indices within"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "009a8b0f-1ec0-45c4-a5f7-d48bfb816a67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reminder: if i_true is a key in knn_indices, then knn_indices[i_true] is a\n",
    "# tuple containing\n",
    "# 1. A NearestNeighbor object fitted on...\n",
    "# 2. ... the set of correctly clustered samples\n",
    "\n",
    "for i_true, (knn, v) in knn_indices.items():\n",
    "    assert len(v) == p_cc[i_true].sum() == knn.n_samples_fit_\n",
    "    w = latent_embeddings[p_cc[i_true]]\n",
    "    assert v.shape == w.shape\n",
    "    assert (v == w).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3562422-f968-4517-b6a0-6472ac8116a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's start with a random entry knn_indices dict\n",
    "\n",
    "i_true, (knn, v) = next(iter(knn_indices.items()))\n",
    "logging.info(\"i_true={}, v.shape={}\", i_true, v.shape)\n",
    "logging.info(\"Matched clusters ({}): {}\", len(matching[i_true]), matching[i_true])\n",
    "\n",
    "n = sum((y_clst == j_clst).sum() for j_clst in matching[i_true])\n",
    "logging.info(\"Nb. of samples in matched clusters: {}\", n)\n",
    "logging.info(\"Nb. of correctly clustered samples: {}\", p_cc[i_true].sum())\n",
    "logging.info(\"Nb. of misclustered samples: {}\", p_mc[i_true].sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50ea3ad5-81cf-421c-937d-ccbb8a784167",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nlnas.correction.clustering import lcc_targets\n",
    "\n",
    "targets = lcc_targets(\n",
    "    torch.tensor(latent_embeddings), y_true, y_clst, matching, knn_indices\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "857c419e-b7b9-4723-bec9-ea2b11300611",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make sure that the target tensors look like what's expected\n",
    "\n",
    "# First, there should be a target entry for each knn index\n",
    "assert set(knn_indices.keys()) == set(targets.keys())\n",
    "\n",
    "for i_true, (p, t) in targets.items():\n",
    "    # p should point to misclusterd samples in true class i_true\n",
    "    assert (p == p_mc[i_true]).all()\n",
    "    assert (y_true[p] == i_true).all()\n",
    "    # Shape of individual targets are what's expected\n",
    "    assert t.shape[1:] == latent_embeddings.shape[1:]\n",
    "    # There are as many targets as there are misclustered samples (in i_true)\n",
    "    assert t.shape[0] == p.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8905f2ad-71e0-4673-ac89-6fe6423746a1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f49d20cc-4bcc-4c7a-bb26-b6c8580e2fb0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9d801d5-f391-439a-8fa6-761d50f520e6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bdde11dc-ed64-463d-a5f1-ba42ecc7216d",
   "metadata": {},
   "source": [
    "## Confusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0faf800f-5c8f-41bb-92d6-72730b83f12b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nlnas.correction.choice import confusion_graph, heaviest_connected_subgraph\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "\n",
    "graph = confusion_graph(y_pred, y_true, n_classes=len(np.unique(y_true)), threshold=10)\n",
    "nx.draw_spring(graph, with_labels=True, node_size=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1ce9a02-dbb4-41c1-9114-989f429559a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "hcsg, w = heaviest_connected_subgraph(graph)\n",
    "logging.info(\n",
    "    \"Top connected confusion: {} labels, {} confused samples\", len(hcsg), int(w)\n",
    ")\n",
    "nx.draw_spring(hcsg, with_labels=True, node_size=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2de0621e-d90e-4423-8150-32753ba8046c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nlnas.correction.choice import top_confusion_pairs\n",
    "\n",
    "tcp5 = top_confusion_pairs(y_pred, y_true, n_classes=len(np.unique(y_true)), n_pairs=5)\n",
    "a, b = tcp5[0]\n",
    "logging.info(\n",
    "    \"Top confusion pair: {}, {} confused samples\",\n",
    "    tcp,\n",
    "    graph.edges[a, b][\"weight\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dfecb3c-bc44-49a5-a5cb-84838bb14a26",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = np.where(((y_true == a) & (y_pred == b)) | ((y_true == b) & (y_pred == a)))[0]\n",
    "logging.info(\"Indices of {}/{} confused samples:\\n{}\", a, b, idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d04b29a-dae5-4ee2-a9cc-95c09e8c54d4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bd77b0d-64a8-4916-98f5-5f179a23a775",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bf7d247-b64f-447d-b9e0-623dc84312c3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlnas",
   "language": "python",
   "name": "nlnas"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
