{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec5c3846-8471-4e22-9f92-65bb65eb6f75",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext jupyter_black\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c27301d3-1afe-4924-957a-574510dec96b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import turbo_broccoli as tb\n",
    "\n",
    "OUTPUT_DIR = Path(\"out.test\")\n",
    "\n",
    "RESULT_FILE_PATH = (\n",
    "    OUTPUT_DIR\n",
    "    / \"microsoft-cats_vs_dogs\"\n",
    "    / \"alexnet\"\n",
    "    / \"results.0e37da4ab09345e4a1eadfe4aef78bbd.json\"\n",
    ")\n",
    "\n",
    "RESULT_FILE_PATH = (\n",
    "    OUTPUT_DIR\n",
    "    / \"timm-eurosat-rgb\"\n",
    "    / \"timm-vgg11.tv_in1k\"\n",
    "    / \"results.6e99633302094c71b965b81b4d128df0.json\"\n",
    ")\n",
    "\n",
    "RESULT_FILE_PATH = (\n",
    "    OUTPUT_DIR\n",
    "    / \"cifar10\"\n",
    "    / \"microsoft-resnet-18\"\n",
    "    / \"results.cdb406564f0d4da98c3b4c0f54958d62.json\"\n",
    ")\n",
    "\n",
    "results = tb.load(RESULT_FILE_PATH)\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59621afe-3698-43a8-a620-df14c21764b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lcc.classifiers import get_classifier_cls\n",
    "\n",
    "MODEL_NAME = results[\"model\"][\"name\"]\n",
    "CKPT_PATH = OUTPUT_DIR / results[\"training\"][\"best_checkpoint\"][\"path\"]\n",
    "\n",
    "cls = get_classifier_cls(MODEL_NAME)\n",
    "model = cls.load_from_checkpoint(CKPT_PATH)\n",
    "model.to(\"cuda\")\n",
    "model.hparams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49e810bf-52e3-41e2-a08c-56c28c8a070e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lcc.datasets import HuggingFaceDataset\n",
    "\n",
    "DATASET_NAME = results[\"dataset\"][\"name\"]\n",
    "\n",
    "dl_kw = {\"batch_size\": 64, \"num_workers\": 8}\n",
    "dataset = HuggingFaceDataset(\n",
    "    dataset_name=DATASET_NAME,\n",
    "    fit_split=results[\"dataset\"][\"train_split\"],\n",
    "    val_split=results[\"dataset\"][\"val_split\"],\n",
    "    test_split=results[\"dataset\"][\"test_split\"],\n",
    "    label_key=results[\"dataset\"][\"label_key\"],\n",
    "    train_dl_kwargs=dl_kw,\n",
    "    image_processor=cls.get_image_processor(MODEL_NAME),\n",
    ")\n",
    "dataset.setup(\"fit\")\n",
    "dl = dataset.train_dataloader()\n",
    "y_true = dataset.y_true(\"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "448ce856-9e9c-42c7-bead-deff099cea27",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "import torch\n",
    "\n",
    "N_SAMPLES = 4000\n",
    "\n",
    "SUBMODULES = [\n",
    "    # \"model.features.0\",\n",
    "    # \"model.features.3\",\n",
    "    \"model.features.6\",\n",
    "    \"model.features.8\",\n",
    "    \"model.features.10\",\n",
    "    \"model.classifier.1\",\n",
    "    \"model.classifier.4\",\n",
    "    # \"model.classifier.6\",\n",
    "]\n",
    "\n",
    "SUBMODULES = [\n",
    "    # \"model.features.0\",\n",
    "    # \"model.features.3\",\n",
    "    \"model.features.6\",\n",
    "    # \"model.features.8\",\n",
    "    \"model.features.11\",\n",
    "    # \"model.features.13\",\n",
    "    \"model.features.16\",\n",
    "    \"model.features.18\",\n",
    "    \"model.pre_logits.fc1\",\n",
    "    # \"model.head\",\n",
    "]\n",
    "\n",
    "SUBMODULES = [\n",
    "    # \"model.resnet.embedder\",\n",
    "    # \"model.resnet.encoder.stages.0\",\n",
    "    \"model.resnet.encoder.stages.1.layers.0.layer.1.convolution\",\n",
    "    \"model.resnet.encoder.stages.2.layers.1.layer.1.convolution\",\n",
    "    \"model.resnet.encoder.stages.3.layers.0.layer.0.convolution\",\n",
    "    \"model.resnet.encoder.stages.3.layers.0.layer.1.convolution\",\n",
    "    \"model.resnet.encoder.stages.3.layers.1.layer.0.convolution\",\n",
    "    # \"model.resnet.encoder.stages.3.layers.1.layer.1.convolution\",\n",
    "    # \"model.classifier\",\n",
    "]\n",
    "\n",
    "n_seen, _data = 0, []\n",
    "for batch in tqdm(dl):\n",
    "    out = {}\n",
    "    model.forward_intermediate(batch, SUBMODULES, out)\n",
    "    out = {k: v.flatten(1) for k, v in out.items()}\n",
    "    _data.append(out)\n",
    "    n_seen += len(next(iter(out.values())))\n",
    "    if n_seen >= N_SAMPLES:\n",
    "        break\n",
    "\n",
    "z = {sm: torch.cat([r[sm] for r in _data])[:N_SAMPLES] for sm in SUBMODULES}\n",
    "for k, v in z.items():\n",
    "    print(k, \":\", v.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02ca0278-73e5-48db-a38e-30cde5f9a291",
   "metadata": {},
   "outputs": [],
   "source": [
    "from cuml import UMAP\n",
    "\n",
    "from lcc.utils import to_array\n",
    "\n",
    "e = {}\n",
    "for sm, u in tqdm(z.items()):\n",
    "    e[sm] = UMAP().fit_transform(to_array(u))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49ff6118-a6c5-4291-adc7-ca788dc4cbf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bokeh.io import output_notebook\n",
    "\n",
    "output_notebook()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8fdded3-686a-4570-a201-cabac8c58691",
   "metadata": {},
   "outputs": [],
   "source": [
    "import bokeh.plotting as bk\n",
    "import bokeh.layouts as bkl\n",
    "import bokeh.palettes as bkp\n",
    "\n",
    "from lcc.plotting import class_scatter\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "\n",
    "SIZE = 250\n",
    "\n",
    "figures = []\n",
    "for sm, u in e.items():\n",
    "    fig = bk.figure(width=SIZE, height=SIZE)\n",
    "    fig.toolbar_location = None\n",
    "    class_scatter(\n",
    "        fig,\n",
    "        u,\n",
    "        y_true[:N_SAMPLES],\n",
    "        grid_visible=False,\n",
    "    )\n",
    "    figures.append(fig)\n",
    "\n",
    "fig = bkl.row(figures)\n",
    "bk.show(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3408a15-a6d2-4749-a68b-8fa4cf10a34a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lcc.plotting import export_png\n",
    "\n",
    "export_png(fig, f\"{MODEL_NAME.replace('/', '-')}_{DATASET_NAME.replace('/', '-')}.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8559dee3-dccd-4b65-aae6-0d9beaf8a420",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f4fbd47-22de-4192-b2f0-6fd09c6ca562",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlnas",
   "language": "python",
   "name": "nlnas"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
