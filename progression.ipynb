{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3a37cb1d-bcf6-4f3a-9aac-ce1ff44e74cf",
   "metadata": {},
   "source": [
    "Compares latent space structure of a model throughout training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51858d9f-23c3-471e-993e-a2ae08a15167",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext jupyter_black\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55ff360b-c957-49f9-810a-4162416b63eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import bokeh.layouts as bkl\n",
    "import bokeh.plotting as bk\n",
    "from bokeh.io import output_notebook\n",
    "\n",
    "from nlnas.plotting import export_png\n",
    "\n",
    "output_notebook()\n",
    "\n",
    "import sys\n",
    "\n",
    "from loguru import logger as logging\n",
    "\n",
    "logging.remove()\n",
    "logging.add(\n",
    "    sys.stdout,\n",
    "    level=\"INFO\",\n",
    "    format=\"[<level>{level: <8}</level>] <level>{message}</level>\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04e0fade-ac07-44b0-8ab8-0e01628351bf",
   "metadata": {},
   "source": [
    "# Prepare stuff"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46660e49-d64c-4c72-9b13-cd4f277b9422",
   "metadata": {},
   "source": [
    "## Find all checkpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a54cf1d4-7a92-4e63-b598-c1c5b6bb66b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import turbo_broccoli as tb\n",
    "\n",
    "HF_DATASET_NAME = \"cifar100\"\n",
    "\n",
    "HF_MODEL_NAME = \"microsoft/resnet-18\"\n",
    "SUBMODULES = [\n",
    "    \"resnet.encoder.stages.0.layers.0\",\n",
    "    \"resnet.encoder.stages.0.layers.1\",\n",
    "    \"resnet.encoder.stages.1.layers.0\",\n",
    "    \"resnet.encoder.stages.1.layers.1\",\n",
    "    \"resnet.encoder.stages.2.layers.0\",\n",
    "    \"resnet.encoder.stages.2.layers.1\",\n",
    "    \"resnet.encoder.stages.3.layers.0\",\n",
    "    \"resnet.encoder.stages.3.layers.1\",\n",
    "    \"classifier\",\n",
    "]\n",
    "\n",
    "# HF_MODEL_NAME = \"timm/mobilenetv3_small_050.lamb_in1k\"\n",
    "# SUBMODULES = [\n",
    "#     \"model.blocks.0\",\n",
    "#     \"model.blocks.1.0\",\n",
    "#     \"model.blocks.1.1\",\n",
    "#     \"model.blocks.2.0\",\n",
    "#     \"model.blocks.2.1\",\n",
    "#     \"model.blocks.2.2\",\n",
    "#     \"model.blocks.3.0\",\n",
    "#     \"model.blocks.3.1\",\n",
    "#     \"model.blocks.4.0\",\n",
    "#     \"model.blocks.4.1\",\n",
    "#     \"model.blocks.4.2\",\n",
    "#     \"model.blocks.5\",\n",
    "#     \"model.conv_head\",\n",
    "#     \"model.classifier\",\n",
    "# ]\n",
    "\n",
    "# HF_MODEL_NAME = \"timm/tinynet_e.in1k\"\n",
    "# SUBMODULES = [f\"model.blocks.{i}\" for i in range(7)] + [\n",
    "#     \"model.conv_head\",\n",
    "#     \"model.classifier\",\n",
    "# ]\n",
    "\n",
    "\n",
    "VERSION = 0\n",
    "\n",
    "DATASET_NAME = HF_DATASET_NAME.replace(\"/\", \"-\")\n",
    "MODEL_NAME = HF_MODEL_NAME.replace(\"/\", \"-\")\n",
    "\n",
    "RESULT_FILE_PATH = (\n",
    "    Path(\"out/ftlcc\") / DATASET_NAME / MODEL_NAME / f\"results.{VERSION}.json\"\n",
    ")\n",
    "RESULTS = tb.load_json(RESULT_FILE_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a720d7d2-d212-4156-a494-db7609c99a24",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nlnas.training import all_checkpoint_paths\n",
    "\n",
    "ckpts = all_checkpoint_paths(\n",
    "    Path(\"out/ftlcc\")\n",
    "    / DATASET_NAME\n",
    "    / MODEL_NAME\n",
    "    / \"tb_logs\"\n",
    "    / MODEL_NAME\n",
    "    / f\"version_{VERSION}\"\n",
    ")\n",
    "\n",
    "logging.info(\"Found {} checkpoints\", len(ckpts))\n",
    "logging.info(\"Best epoch: {}\", RESULTS[\"model\"][\"best_checkpoint\"][\"best_epoch\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5125294d-4976-434f-b1aa-7f700b1e6cfd",
   "metadata": {},
   "source": [
    "## Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73805a33-da67-4180-a178-7fbe159f70d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nlnas.datasets.huggingface import HuggingFaceDataset\n",
    "from nlnas.classifiers.timm import TimmClassifier\n",
    "from nlnas.classifiers.base import BaseClassifier\n",
    "from nlnas.classifiers.huggingface import HuggingFaceClassifier\n",
    "from nlnas.utils import get_reasonable_n_jobs\n",
    "\n",
    "classifier_cls: type[BaseClassifier]\n",
    "if HF_MODEL_NAME.startswith(\"timm/\"):\n",
    "    classifier_cls = TimmClassifier\n",
    "else:\n",
    "    classifier_cls = HuggingFaceClassifier\n",
    "\n",
    "dataset = HuggingFaceDataset(\n",
    "    HF_DATASET_NAME,\n",
    "    fit_split=RESULTS[\"dataset\"][\"train_split\"],\n",
    "    val_split=RESULTS[\"dataset\"][\"val_split\"],\n",
    "    test_split=RESULTS[\"dataset\"][\"test_split\"],\n",
    "    predict_split=RESULTS[\"dataset\"][\"train_split\"],  # not a typo\n",
    "    train_dl_kwargs={\n",
    "        \"batch_size\": 64,\n",
    "        \"num_workers\": get_reasonable_n_jobs(),\n",
    "    },\n",
    "    label_key=RESULTS[\"dataset\"][\"label_key\"],\n",
    "    image_processor=classifier_cls.get_image_processor(HF_MODEL_NAME),\n",
    ")\n",
    "\n",
    "y_true = dataset.y_true(\"train\").numpy()\n",
    "n_classes, n_samples = dataset.n_classes(), len(y_true)\n",
    "logging.info(\"y_true: {}\", y_true.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d57fbd7-465e-48d7-9ca5-35fdb386818d",
   "metadata": {},
   "source": [
    "# Full DS clustering on every epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24b69f1b-aa07-4c27-aa8b-193f4fad32b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "CLUSTERING_METHOD = \"louvain\"\n",
    "PLOTS_PATH = Path(\"out/ftlcc\") / DATASET_NAME / MODEL_NAME / \"analysis\" / str(VERSION)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "149185f0-3db1-42f9-ae17-bc8c026da8ce",
   "metadata": {},
   "source": [
    "## Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dc22670-60ff-4de1-8111-e7a7ea37ffc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tempfile import TemporaryDirectory\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from nlnas.classifiers.timm import TimmClassifier\n",
    "from nlnas.classifiers.base import full_dataset_latent_clustering\n",
    "from nlnas.training import checkpoint_ves\n",
    "\n",
    "lc_data = {}\n",
    "\n",
    "for ckpt in tqdm(ckpts):\n",
    "    _, epoch, _ = checkpoint_ves(ckpt)\n",
    "    output_dir = (\n",
    "        Path(\"out/ftlcc\")\n",
    "        / DATASET_NAME\n",
    "        / MODEL_NAME\n",
    "        / \"analysis\"\n",
    "        / str(VERSION)\n",
    "        / str(epoch)\n",
    "    )\n",
    "    (output_dir / \"louvain\").mkdir(exist_ok=True, parents=True)\n",
    "    g = tb.GuardedBlockHandler(output_dir / CLUSTERING_METHOD / \"data.json\")\n",
    "    for _ in g:\n",
    "        with TemporaryDirectory() as tmp:\n",
    "            model = classifier_cls.load_from_checkpoint(ckpt)\n",
    "            model.hparams[\"lcc_submodules\"] = SUBMODULES\n",
    "            data = full_dataset_latent_clustering(\n",
    "                model=model,\n",
    "                dataset=dataset,\n",
    "                output_dir=tmp,\n",
    "                method=CLUSTERING_METHOD,\n",
    "                device=\"cuda\",\n",
    "                tqdm_style=\"notebook\",\n",
    "            )\n",
    "            g.result = {sm: (d.y_clst, d.matching) for sm, d in data.items()}\n",
    "    lc_data[epoch] = g.result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d821cece-956e-48c9-9f06-08d873b6f369",
   "metadata": {},
   "source": [
    "## Basic plots (r_clst, r_cc, r_mc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbf20c4b-2269-4cd7-a899-e6a2238be026",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from nlnas.correction.clustering import otm_matching_predicates, _mc_cc_predicates\n",
    "\n",
    "data = []\n",
    "for epoch, d in tqdm(lc_data.items()):\n",
    "    for sm, (y_clst, matching) in d.items():\n",
    "        p_mc, p_cc = _mc_cc_predicates(y_true, y_clst, matching)\n",
    "        row = {\n",
    "            \"epoch\": epoch,\n",
    "            \"sm\": sm,\n",
    "            \"r_clst\": len(np.unique(y_clst)) / n_classes,\n",
    "            \"r_cc\": p_cc.sum() / n_samples,\n",
    "            \"r_mc\": p_mc.sum() / n_samples,\n",
    "        }\n",
    "        data.append(row)\n",
    "\n",
    "df = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94114b5a-f922-4bf0-878f-0bdfcb7abfc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "ax = sns.lineplot(data=df, x=\"epoch\", y=\"r_clst\", hue=\"sm\")\n",
    "sns.move_legend(ax, \"upper left\", bbox_to_anchor=(1, 1))\n",
    "ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "214d9bc4-7cfc-4d90-a243-9ded4bc1cb13",
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = sns.lineplot(data=df, x=\"epoch\", y=\"r_cc\", hue=\"sm\")\n",
    "sns.move_legend(ax, \"upper left\", bbox_to_anchor=(1, 1))\n",
    "ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a00b7858-cdc9-47c0-9144-ca45d91bb738",
   "metadata": {},
   "outputs": [],
   "source": [
    "ax.get_figure().savefig(\n",
    "    str(PLOTS_PATH / f\"{CLUSTERING_METHOD}.r_cc_by_epoch_by_sm.png\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71f4f6e2-4e58-4f00-afad-a4f53f9978d7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2d32d68c-de17-4ea6-bb55-4cbb23d5d00f",
   "metadata": {},
   "source": [
    "# Tracking\n",
    "\n",
    "In this section, we track samples and the clusters they belong to across latent spaces"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6b0e539-df8f-4342-a731-9d282385f949",
   "metadata": {},
   "source": [
    "## Tracing the true label owning the cluster owning the sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2472ff55-2535-417f-bc09-67c8c0b9fbaa",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# First, get the array of all predictions\n",
    "# y_preds: (n_epochs, N)\n",
    "\n",
    "\n",
    "from tempfile import TemporaryDirectory\n",
    "\n",
    "import pytorch_lightning as pl\n",
    "import torch\n",
    "\n",
    "torch.set_float32_matmul_precision(\"medium\")\n",
    "\n",
    "_yps = []\n",
    "for ckpt in ckpts:\n",
    "    model = TimmClassifier.load_from_checkpoint(ckpt)\n",
    "    with TemporaryDirectory() as tmp:\n",
    "        trainer = pl.Trainer(\n",
    "            callbacks=[pl.callbacks.TQDMProgressBar()], default_root_dir=tmp\n",
    "        )\n",
    "        logit_batches = trainer.predict(model, dataset)\n",
    "    y_pred = torch.cat(logit_batches).argmax(dim=-1).numpy()\n",
    "    _yps.append(y_pred)\n",
    "\n",
    "y_preds = np.array(_yps, dtype=int)\n",
    "y_preds.shape"
   ]
  },
  {
   "cell_type": "raw",
   "id": "3de5a3b6-685c-48e7-907a-0aec88020ab1",
   "metadata": {},
   "source": [
    "# Load all the predictions\n",
    "# y_preds[e, j] is the label prediction of sample j at epoch e\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "from nlnas.utils import load_tensor_batched\n",
    "import torch\n",
    "\n",
    "_yps = [\n",
    "    load_tensor_batched(\n",
    "        (\n",
    "            Path(\"out/ftlcc\")\n",
    "            / DATASET_NAME\n",
    "            / MODEL_NAME\n",
    "            / \"analysis\"\n",
    "            / str(VERSION)\n",
    "            / str(epoch)\n",
    "            / \"embeddings\"\n",
    "            / \"train\"\n",
    "        ),\n",
    "        prefix=\"y_pred\",\n",
    "        tqdm_style=\"notebook\",\n",
    "    ).argmax(dim=-1)\n",
    "    for epoch in tqdm(lc_data.keys())\n",
    "]\n",
    "y_preds = torch.stack(_yps).numpy()\n",
    "y_preds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ac665b8-2984-43ed-91aa-56f3aa5abaf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Want a boolean array containing matching predictions\n",
    "# The matching prediction of a sample j is i_true if i_true owns the cluster of\n",
    "# sample j\n",
    "# y_match[epoch, sm, j] is the true label that owns the cluster of sample j, at\n",
    "# epoch e\n",
    "# For example, in a super ideal world, y_match[e, s, j] would always be the true\n",
    "# label of j, at least for the best epoch e\n",
    "\n",
    "# Relevant OTM predicate: p2 since p2[i_true, j] is true if j is in a cluster\n",
    "# owned by true class i_true\n",
    "\n",
    "_yms = []\n",
    "for epoch, d in tqdm(lc_data.items()):\n",
    "    u = []\n",
    "    for sm, (y_clst, matching) in tqdm(d.items(), leave=False):\n",
    "        _, p2, _, _ = otm_matching_predicates(y_true, y_clst, matching)\n",
    "        # (N,), y_clst_true[j] = true class that owns j's cluster\n",
    "        y_clst_true = p2.argmax(axis=0)\n",
    "        u.append(y_clst_true)\n",
    "    _yms.append(u)\n",
    "\n",
    "y_match = np.array(_yms, dtype=int)\n",
    "y_match.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "437524a3-6fb2-4a96-bbcc-50bfdd9c36c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Computing the accuracy of the matching predictions\n",
    "\n",
    "# match_accs: (n_epochs, n_submods)\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "_ma = [\n",
    "    [accuracy_score(y_true, b) for b in a]  # a: (N,)\n",
    "    for a in y_match  # a: (n_submods, N)\n",
    "]\n",
    "\n",
    "match_accs = np.array(_ma)\n",
    "match_accs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfded9ea-5609-4499-81f3-52f53e5d79b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "d = []\n",
    "for e, v in enumerate(match_accs):\n",
    "    for sm, a in zip(SUBMODULES, v):\n",
    "        d.append({\"epoch\": e, \"sm\": sm, \"acc\": a})\n",
    "\n",
    "df = pd.DataFrame(d)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4dd3110-9afd-4a73-8b82-efa088a9afe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = sns.lineplot(data=df, x=\"epoch\", y=\"acc\", hue=\"sm\")\n",
    "sns.move_legend(ax, \"upper left\", bbox_to_anchor=(1, 1))\n",
    "ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0a6eead-a486-43fe-99bb-bf45358b0169",
   "metadata": {},
   "outputs": [],
   "source": [
    "ax.get_figure().savefig(\n",
    "    str(PLOTS_PATH / f\"{CLUSTERING_METHOD}.clst_acc_by_epoch_by_sm.png\")\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6663194-be05-4db1-be0f-181bec478016",
   "metadata": {},
   "source": [
    "# Cluster diffraction\n",
    "\n",
    "Look at a latent cluster and see how its samples are clustered in the next LS "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ae6df02-8a01-418a-b41a-bdd1da23eabf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Array containing all diffractions of submodules in SUBMODULES\n",
    "# (except the first one)\n",
    "# difts: (n_epochs, s) where s represents module SUBMODULES[s+1]\n",
    "\n",
    "from itertools import pairwise\n",
    "from nlnas.correction.clustering import class_otm_matching\n",
    "\n",
    "\n",
    "def diffraction(y_clst_1: np.ndarray, y_clst_2: np.ndarray) -> float:\n",
    "    matching = class_otm_matching(y_clst_1, y_clst_2)\n",
    "    _, _, p3, _ = otm_matching_predicates(y_clst_1, y_clst_2, matching)\n",
    "    return p3.sum() / len(y_clst_1)\n",
    "\n",
    "\n",
    "_dfs = []\n",
    "for epoch, d in tqdm(lc_data.items()):\n",
    "    all_y_clst = [v[0] for v in d.values()]\n",
    "    _dfs.append(\n",
    "        [\n",
    "            diffraction(yc1, yc2)\n",
    "            for yc1, yc2 in tqdm(list(pairwise(all_y_clst)), leave=False)\n",
    "        ]\n",
    "    )\n",
    "\n",
    "difts = np.array(_dfs)\n",
    "difts.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d792fdd4-b1ca-4d73-9236-5ce8c71d4e30",
   "metadata": {},
   "outputs": [],
   "source": [
    "_data = []\n",
    "for epoch, v in enumerate(difts):\n",
    "    for sm, d in zip(SUBMODULES[1:], v):\n",
    "        _data.append({\"epoch\": epoch, \"sm\": sm, \"d\": d})\n",
    "\n",
    "df = pd.DataFrame(_data)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cda8ce7a-7098-4bd5-b5b9-3cb2833a52b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "g = sns.FacetGrid(data=df, col=\"sm\", col_wrap=3)\n",
    "g.map(sns.lineplot, \"epoch\", \"d\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6a2a586-a4e3-45dc-90b7-53c3a213b877",
   "metadata": {},
   "outputs": [],
   "source": [
    "g.fig.savefig(str(PLOTS_PATH / f\"{CLUSTERING_METHOD}.diffraction_by_epoch_by_sm.png\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abb18ee9-8a06-42ae-a9f2-0498e4e36c9f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9049685-7dcd-44e7-84a4-3eb3960acfc1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3f9ae68-ebf3-4c8e-8632-b269dd8aadcb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b6e70223-f683-4b0b-aac2-c0f8bedb9d93",
   "metadata": {},
   "source": [
    "# Class diffraction\n",
    "\n",
    "Look at a true class and look where the samples in its matched clusters go in the next LS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55fc6e8e-568f-4aa2-9809-07ca222da91b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fdf1744-460e-44ac-93df-a549d5a6a5a9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b95f63d6-9d16-4a39-b268-814d8bf57b85",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2da8815e-53c6-4bee-8d46-85163458bcd4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f39978d5-72cd-4ef0-a7cf-48875833f934",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9c99b94-9549-47e3-87b1-ee322667121f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3564c13b-071f-4ea6-8659-7d4662a70811",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db705826-a922-40f7-98bd-011303cfb4fc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5473492f-dba1-46bc-82b9-c34700551b89",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57911e1d-400a-4b29-bd88-8795e06ac8cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nlnas.classifiers import BaseClassifier\n",
    "from nlnas import HuggingFaceClassifier, TimmClassifier\n",
    "\n",
    "ClassifierClass: type[BaseClassifier]\n",
    "if HF_MODEL_NAME.startswith(\"timm/\"):\n",
    "    ClassifierClass = TimmClassifier\n",
    "else:\n",
    "    ClassifierClass = HuggingFaceClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b6d9d97-b51d-4fca-a58e-972d48867f1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "FT_CKPT_PATH = Path(\"out\") / \"ft\" / FT_RESULTS[\"fine_tuning\"][\"best_checkpoint\"][\"path\"]\n",
    "FT_MODEL = ClassifierClass.load_from_checkpoint(FT_CKPT_PATH)\n",
    "\n",
    "LCC_CKPT_PATH = (\n",
    "    Path(\"out\") / \"lcc\" / LCC_RESULTS[\"correction\"][\"best_checkpoint\"][\"path\"]\n",
    ")\n",
    "LCC_MODEL = ClassifierClass.load_from_checkpoint(LCC_CKPT_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d77ae9a5-3d5a-439e-aca9-24cca80f6738",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nlnas import HuggingFaceDataset\n",
    "\n",
    "DATASET = HuggingFaceDataset(\n",
    "    HF_DATASET_NAME,\n",
    "    fit_split=FT_RESULTS[\"dataset\"][\"train_split\"],\n",
    "    val_split=FT_RESULTS[\"dataset\"][\"val_split\"],\n",
    "    test_split=FT_RESULTS[\"dataset\"][\"test_split\"],\n",
    "    predict_split=FT_RESULTS[\"dataset\"][\"train_split\"],  # not a typo\n",
    "    label_key=FT_RESULTS[\"dataset\"][\"label_key\"],\n",
    "    image_processor=ClassifierClass.get_image_processor(HF_MODEL_NAME),\n",
    ")\n",
    "\n",
    "Y_TRUE = dataset.y_true(\"train\").numpy()\n",
    "Y_TRUE.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ca97b49-ee7a-40f0-ab17-a141f3f8a95b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tempfile import TemporaryDirectory\n",
    "\n",
    "import pytorch_lightning as pl\n",
    "import torch\n",
    "import turbo_broccoli as tb\n",
    "\n",
    "g = tb.GuardedBlockHandler(FT_PATH / \"lc\" / \"y_pred.st\")\n",
    "for _ in g.guard():\n",
    "    with TemporaryDirectory() as tmp:\n",
    "        trainer = pl.Trainer(\n",
    "            callbacks=pl.callbacks.TQDMProgressBar(),\n",
    "            default_root_dir=tmp,\n",
    "        )\n",
    "        data = trainer.predict(FT_MODEL, DATASET)\n",
    "    g.result = {\"\": torch.concat(data).numpy()}\n",
    "FT_Y_PRED = g.result[\"\"].argmax(axis=-1)\n",
    "FT_Y_PRED.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13a19ac1-b3ed-4c12-bfeb-c0600ccf9e5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "g = tb.GuardedBlockHandler(LCC_PATH / \"lc\" / \"y_pred.st\")\n",
    "for _ in g.guard():\n",
    "    with TemporaryDirectory() as tmp:\n",
    "        trainer = pl.Trainer(\n",
    "            callbacks=pl.callbacks.TQDMProgressBar(),\n",
    "            default_root_dir=tmp,\n",
    "        )\n",
    "        data = trainer.predict(LCC_MODEL, DATASET)\n",
    "    g.result = {\"\": torch.concat(data).numpy()}\n",
    "LCC_Y_PRED = g.result[\"\"].argmax(axis=-1)\n",
    "LCC_Y_PRED.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66953c6b-d0d6-4d8d-b072-058d715173f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Truncate the dataset to only consider DD_N_SAMPLES samples for distance\n",
    "# distribution computations\n",
    "DD_N_SAMPLES = 10000\n",
    "\n",
    "# For DD histograms\n",
    "RESOLUTION = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fc34da2-adc5-4cef-a380-9da0d05c8ec4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import turbo_broccoli as tb\n",
    "\n",
    "from nlnas.analysis.dd import distance_distribution\n",
    "\n",
    "# Full dataset distance distribution (DD) data\n",
    "# Each entry in the dict is itself a dict with three entries:\n",
    "# - `d`: the pdist distance matrix (it's actually just a flat vector but whatever)\n",
    "# - `hist` (RESOLUTION,): histogram counts\n",
    "# - `edges` (RESOLUTION + 1,): histogram bin edges\n",
    "\n",
    "g = tb.GuardedBlockHandler(\n",
    "    FT_PATH / \"lc\" / \"pdist\" / \"train\" / \"full\" / (SUBMODULE + \".st\")\n",
    ")\n",
    "for _ in g.guard():\n",
    "    h, e = distance_distribution(FT_LE[:DD_N_SAMPLES])\n",
    "    g.result = {\"hist\": h, \"edges\": e}\n",
    "FT_DD_FULL = g.result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6add6be-dd35-4c78-9d20-90b454af33ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "g = tb.GuardedBlockHandler(\n",
    "    LCC_PATH / \"lc\" / \"pdist\" / \"train\" / \"full\" / (SUBMODULE + \".st\")\n",
    ")\n",
    "for _ in g.guard():\n",
    "    h, e = distance_distribution(LCC_LE[:DD_N_SAMPLES])\n",
    "    g.result = {\"hist\": h, \"edges\": e}\n",
    "LCC_DD_FULL = g.result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1001765-3cd2-48cc-996d-93b91f07169c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nlnas.analysis.dd import distance_distribution_plot\n",
    "\n",
    "SIZE = 250\n",
    "\n",
    "ft_dd_plot = distance_distribution_plot(\n",
    "    FT_DD_FULL[\"hist\"], FT_DD_FULL[\"edges\"], height=SIZE, n_dims=FT_LE.shape[-1]\n",
    ")\n",
    "ft_dd_plot.title = (\n",
    "    f\"[After fine-tuning] full DD, sm={SUBMODULE}, n_dims={FT_LE.shape[-1]}\"\n",
    ")\n",
    "\n",
    "lcc_dd_plot = distance_distribution_plot(\n",
    "    LCC_DD_FULL[\"hist\"], LCC_DD_FULL[\"edges\"], height=SIZE, n_dims=LCC_LE.shape[-1]\n",
    ")\n",
    "lcc_dd_plot.title = f\"[After LCC] full DD, sm={SUBMODULE}, n_dims={LCC_LE.shape[-1]}\"\n",
    "\n",
    "figure = bkl.column([ft_dd_plot, lcc_dd_plot])\n",
    "bk.show(figure)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e2335ed-862f-4cc3-bb94-a594e9e0d1bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "figure = bk.figure(\n",
    "    height=SIZE,\n",
    "    width=SIZE * 2,\n",
    "    toolbar_location=None,\n",
    "    title=f\"Full DD, after FT (red) vs. after LCC (blue), sm={SUBMODULE}\",\n",
    ")\n",
    "\n",
    "x_range = (0, 1.1 * max(FT_DD_FULL[\"hist\"].max(), LCC_DD_FULL[\"hist\"].max()))\n",
    "figure.line(FT_DD_FULL[\"edges\"][:-1], FT_DD_FULL[\"hist\"], color=\"red\")\n",
    "figure.line(LCC_DD_FULL[\"edges\"][:-1], LCC_DD_FULL[\"hist\"], color=\"blue\")\n",
    "bk.show(figure)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e57df20-0559-45f0-9565-0c1fc43aa6d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Full dataset distance distribution (DD) data\n",
    "# Each entry in the dict is itself a dict with three entries:\n",
    "# - `d`: the pdist distance matrix (it's actually just a flat vector but whatever)\n",
    "# - `hist` (RESOLUTION,): histogram counts\n",
    "# - `edges` (RESOLUTION + 1,): histogram bin edges\n",
    "\n",
    "import turbo_broccoli as tb\n",
    "\n",
    "CLASSES = list(range(20))\n",
    "\n",
    "FT_DD_INTRA = {}\n",
    "for i in tqdm(CLASSES, leave=False):\n",
    "    g = tb.GuardedBlockHandler(\n",
    "        FT_PATH\n",
    "        / \"lc\"\n",
    "        / \"pdist\"\n",
    "        / \"train\"\n",
    "        / \"intra-class\"\n",
    "        / str(i)\n",
    "        / (SUBMODULE + \".st\")\n",
    "    )\n",
    "    for _ in g.guard():\n",
    "        h, e = distance_distribution(FT_LE[y_true == i][:DD_N_SAMPLES])\n",
    "        g.result = {\"hist\": h, \"edges\": e}\n",
    "    FT_DD_INTRA[i] = g.result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e688b8de-ab36-48ea-83b8-13e3240a9647",
   "metadata": {},
   "outputs": [],
   "source": [
    "LCC_DD_INTRA = {}\n",
    "for i in tqdm(CLASSES, leave=False):\n",
    "    g = tb.GuardedBlockHandler(\n",
    "        LCC_PATH\n",
    "        / \"lc\"\n",
    "        / \"pdist\"\n",
    "        / \"train\"\n",
    "        / \"intra-class\"\n",
    "        / str(i)\n",
    "        / (SUBMODULE + \".st\")\n",
    "    )\n",
    "    for _ in g.guard():\n",
    "        h, e = distance_distribution(LCC_LE[y_true == i][:DD_N_SAMPLES])\n",
    "        g.result = {\"hist\": h, \"edges\": e}\n",
    "    LCC_DD_INTRA[i] = g.result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89a293c9-dd19-4698-8409-27d3a4f2ca17",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nlnas.analysis.dd import distance_distribution_plot\n",
    "\n",
    "SIZE = 250\n",
    "\n",
    "figure = bk.figure(height=SIZE, width=2 * SIZE, toolbar_location=None, x_range=(0, 2.5))\n",
    "\n",
    "for i in CLASSES:\n",
    "    figure.line(\n",
    "        FT_DD_INTRA[i][\"edges\"][:-1], FT_DD_INTRA[i][\"hist\"], color=\"red\", width=0.5\n",
    "    )\n",
    "    figure.line(\n",
    "        LCC_DD_INTRA[i][\"edges\"][:-1], LCC_DD_INTRA[i][\"hist\"], color=\"blue\", width=0.5\n",
    "    )\n",
    "\n",
    "bk.show(figure)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12a460d0-6ede-413c-8e1e-0cf79c9c3850",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "figure = bk.figure(height=SIZE, width=2 * SIZE, toolbar_location=None, x_range=(0, 2.5))\n",
    "\n",
    "figure.line(\n",
    "    FT_DD_INTRA[0][\"edges\"][:-1],\n",
    "    np.stack([d[\"hist\"] for d in FT_DD_INTRA.values()]).mean(axis=0),\n",
    "    color=\"red\",\n",
    "    width=1,\n",
    ")\n",
    "figure.line(\n",
    "    LCC_DD_INTRA[0][\"edges\"][:-1],\n",
    "    np.stack([d[\"hist\"] for d in LCC_DD_INTRA.values()]).mean(axis=0),\n",
    "    color=\"blue\",\n",
    "    width=0.5,\n",
    ")\n",
    "\n",
    "bk.show(figure)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58776480-c2f9-4c9c-bd17-27b728b5c186",
   "metadata": {},
   "outputs": [],
   "source": [
    "from cuml import UMAP\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "N_SAMPLES = 10000\n",
    "\n",
    "g = tb.GuardedBlockHandler(FT_PATH / \"lc\" / \"umap\" / \"train\" / (SUBMODULE + \".st\"))\n",
    "for _ in g.guard():\n",
    "    e = UMAP(n_components=2).fit_transform(FT_LE[:N_SAMPLES])\n",
    "    e = MinMaxScaler().fit_transform(e)\n",
    "    g.result = {\"\": e}\n",
    "FT_LE_2D = g.result[\"\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "583f96cd-9540-4654-96b3-1bb1af6410cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "g = tb.GuardedBlockHandler(LCC_PATH / \"lc\" / \"umap\" / \"train\" / (SUBMODULE + \".st\"))\n",
    "for _ in g.guard():\n",
    "    e = UMAP(n_components=2).fit_transform(LCC_LE[:N_SAMPLES])\n",
    "    e = MinMaxScaler().fit_transform(e)\n",
    "    g.result = {\"\": e}\n",
    "LCC_LE_2D = g.result[\"\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a147e2ac-0c4e-4b27-8014-9d3d92cc3128",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nlnas.correction.choice import top_confusion_pairs, max_connected_confusion_choice\n",
    "\n",
    "N_PAIRS = 1\n",
    "\n",
    "n_classes = DATASET.n_classes()\n",
    "ft_top_cp = top_confusion_pairs(FT_Y_PRED, Y_TRUE, n_classes, n_pairs=N_PAIRS)\n",
    "lcc_top_cp = top_confusion_pairs(LCC_Y_PRED, Y_TRUE, n_classes, n_pairs=N_PAIRS)\n",
    "inter_cp = list(set(ft_top_cp).intersection(lcc_top_cp))\n",
    "\n",
    "print(\"FT top confusion pairs:\", ft_top_cp)\n",
    "print(\"LCC top confusion pairs:\", lcc_top_cp)\n",
    "print(f\"In common ({len(inter_cp)} pairs):\", inter_cp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47cb0039-33f2-4f9d-b044-8232de929b55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select samples\n",
    "\n",
    "from more_itertools import flatten, unique\n",
    "\n",
    "# labels = list(unique(flatten(inter_cp)))\n",
    "labels = list(unique(flatten(ft_top_cp)))\n",
    "mask = np.isin(Y_TRUE, labels)\n",
    "print(f\"Base labels (n_lbls={len(labels)}, n_smpls={mask.sum()}):\", labels)\n",
    "\n",
    "# Adding samples form matched clusters\n",
    "\n",
    "ft_matched_lbls = list(flatten(FT_MATCHING[i] for i in labels))\n",
    "msk = np.isin(FT_Y_CLST, ft_matched_lbls)\n",
    "mask |= msk\n",
    "print(\"Adding (at most)\", msk.sum(), \"extra samples from FT matching\")\n",
    "\n",
    "lcc_matched_lbls = list(flatten(LCC_MATCHING[i] for i in labels))\n",
    "msk = np.isin(LCC_Y_CLST, ft_matched_lbls)\n",
    "mask |= msk\n",
    "print(\"Adding (at most)\", msk.sum(), \"extra samples from LCC matching\")\n",
    "\n",
    "print(\"Total:\", mask.sum(), \"samples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ba9fbe1-7d9e-4bc9-a82a-ad00091d5c23",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nlnas.plotting import class_scatter\n",
    "\n",
    "_msk1 = mask[:N_SAMPLES]  # mask to select the from *_LE_2D and\n",
    "\n",
    "_msk2 = np.full_like(Y_TRUE, True, dtype=bool)  # mask to select from *_Y_*\n",
    "_msk2[N_SAMPLES:] = False  # select at most N_SAMPLES samples\n",
    "_msk2 &= mask\n",
    "\n",
    "SIZE = 250\n",
    "kw = {\"width\": SIZE, \"height\": SIZE, \"toolbar_location\": None}\n",
    "\n",
    "logging.info(\"Rendering FT/TRUE\")\n",
    "ft_true = bk.figure(title=\"FT, true\", **kw)\n",
    "class_scatter(ft_true, FT_LE_2D[_msk1], Y_TRUE[_msk2])\n",
    "\n",
    "logging.info(\"Rendering FT/PRED\")\n",
    "ft_pred = bk.figure(title=\"FT, pred\", **kw)\n",
    "class_scatter(ft_pred, FT_LE_2D[_msk1], FT_Y_PRED[_msk2])\n",
    "\n",
    "logging.info(\"Rendering FT/CLST\")\n",
    "ft_clst = bk.figure(title=\"FT, clst\", **kw)\n",
    "class_scatter(ft_clst, FT_LE_2D[_msk1], FT_Y_CLST[_msk2])\n",
    "\n",
    "logging.info(\"Rendering LCC/TRUE\")\n",
    "lcc_true = bk.figure(title=\"LCC, true\", **kw)\n",
    "class_scatter(lcc_true, LCC_LE_2D[_msk1], Y_TRUE[_msk2])\n",
    "\n",
    "logging.info(\"Rendering LCC/PRED\")\n",
    "lcc_pred = bk.figure(title=\"FT, pred\", **kw)\n",
    "class_scatter(lcc_pred, LCC_LE_2D[_msk1], LCC_Y_PRED[_msk2])\n",
    "\n",
    "logging.info(\"Rendering LCC/CLST\")\n",
    "lcc_clst = bk.figure(title=\"LCC, clst\", **kw)\n",
    "class_scatter(lcc_clst, LCC_LE_2D[_msk1], LCC_Y_CLST[_msk2])\n",
    "\n",
    "figure = bkl.column(\n",
    "    [\n",
    "        bkl.row([ft_true, ft_pred, ft_clst]),\n",
    "        bkl.row([lcc_true, lcc_pred, lcc_clst]),\n",
    "    ]\n",
    ")\n",
    "bk.show(figure)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdbcc408-1723-4d30-aae9-38b304926c0c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c62e372-7703-428f-9968-46a76db6ddcb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0288118-0c8d-466f-8556-043ef786205d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a08ad993-026e-4782-8300-98997e7b5cb5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fbe8b86-ea50-42b0-8aca-60ecb23e43ac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4eda484b-6b94-492b-b507-b0bd19dc0456",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44c103a2-4dc3-4473-814f-824e450f843f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlnas",
   "language": "python",
   "name": "nlnas"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
